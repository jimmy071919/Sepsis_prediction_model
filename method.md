# 敗血症預測模型方法論文檔

## 概述

本研究建構一個基於機器學習的敗血症預測模型，使用1886筆醫療數據，結合結構化臨床數據與非結構化文本數據，通過多種機器學習算法進行敗血症風險預測。研究採用嚴格的交叉驗證方法，並針對醫療數據的特殊挑戰進行多項技術優化。

## 1. 數據載入與預處理

### 1.1 數據來源
- **數據規模**: 1886筆患者記錄
- **數據格式**: Excel檔案 (`1141112.xlsx`)
- **目標變量**: isSepsis (二分類：Y/N)
- **特徵變量**: 26個特徵（包含結構化與非結構化數據）
- **類別分布**: 非敗血症1568例，敗血症318例
- **類別不平衡比例**: 4.93:1

### 1.2 缺失值處理策略

#### 缺失值識別
系統性識別多種缺失值表示形式：空字串、空格、N/A、NA、na、n/a、None等，確保數據完整性。

#### 缺失值統計與處理
- **處理方法**: 交叉驗證內部動態填補
- **填補策略**: 使用中位數填補連續變量
- **避免數據洩漏**: 每個fold內部重新計算填補統計值

在每個交叉驗證fold內部進行填補，使用SimpleImputer策略為'median'，先在訓練集上fit，再transform驗證集。

### 1.3 異常值處理詳細記錄

#### 醫學合理性檢驗範圍
建立醫學參考範圍，識別生理不合理數值：
- **體溫 (BT)**: 30-45°C
- **血壓 (SBP/DBP)**: 40-300/20-200 mmHg  
- **平均動脈壓 (MAP)**: 10-300 mmHg
- **BMI**: 10-100 kg/m²
- **脈搏 (Pulse)**: 30-250 次/分
- **住院天數 (LOS)**: 0-10000天

#### 零值異常處理
對於不應為零的生理指標，將零值視為異常：
Weight、WBC、PLT、Crea、T-Bil、Lymph、Segment、PT、PCT、BMI、SBP、DBP、MAP

#### 實際處理記錄統計

**詳細處理記錄表**：
| 欄位 | 原始缺失 | 異常剔除 | 缺失與異常總和 |
|------|----------|----------|----------------|
| BT | 5 | 17 | 22 |
| MAP | 0 | 48 | 48 |
| SBP | 1 | 21 | 22 |
| DBP | 1 | 16 | 17 |
| BMI | 59 | 11 | 70 |
| Height | 59 | 4 | 63 |
| Weight | 20 | 1 | 21 |
| WBC | 431 | 9 | 440 |
| PLT | 449 | 1 | 450 |
| Crea | 461 | 13 | 474 |
| T-Bil | 1070 | 68 | 1138 |
| Lymph | 466 | 4 | 470 |
| Segment | 1501 | 265 | 1766 |
| PT | 1085 | 126 | 1211 |
| PCT | 1540 | 211 | 1751 |
| BOXY | 171 | 0 | 171 |
| Pulse | 1 | 6 | 7 |

**統計總結**：
- 原始資料缺失值: 7,320 格
- 異常值剔除數量: 821 格
- 處理後總缺失值: 8,141 格

#### 處理效果分析
- **高缺失率欄位**: PCT (92.8%)、Segment (93.6%)、PT (64.2%)、T-Bil (60.4%)
- **異常值集中欄位**: Segment (265例)、PCT (211例)、PT (126例)
- **數據品質**: 經處理後確保所有數值皆在醫學合理範圍內

## 2. 數據分割策略

### 2.1 分割比例與方法
- **訓練集**: 67% (1257筆)
- **測試集**: 33% (629筆)
- **分割方法**: 分層抽樣 (stratified split)
- **隨機種子**: 42 (確保可重現性)

### 2.2 類別平衡維持
使用分層抽樣確保訓練集和測試集中敗血症比例保持一致，避免因分割造成的類別分布偏移。

### 2.3 數據洩漏防範
- 嚴格的時間序列分割
- 所有預處理步驟在分割後進行
- 測試集完全隔離，僅用於最終評估

## 3. 特徵嵌入處理

### 3.1 結構化數據處理

#### 特徵選擇與標準化
- **a-x 欄位**: 24個結構化臨床特徵
- **數據類型**: 連續型數值變量
- **標準化方法**: StandardScaler Z-score標準化
- **處理結果**: 訓練集(1257, 24)，測試集(629, 24)

標準化處理確保不同量級的特徵（如體溫vs白血球數量）具有相同的影響權重。

### 3.2 非結構化文本嵌入

#### BERT嵌入處理
- **模型**: BERT中文預訓練模型
- **嵌入維度**: 768維向量表示
- **處理字段**: 
  - `diagnosis` (診斷): y欄位 → 768維向量
  - `chief` (主訴): z欄位 → 768維向量

#### 文本預處理流程
1. 使用BERT tokenizer進行文本分詞
2. 設定最大長度為512個token，超出部分截斷
3. 獲取last_hidden_state的平均值作為文本表示

#### 缺失文本處理策略 (但文本內容沒有缺失值)
- **策略**: 使用768維零向量表示缺失文本
- **優點**: 保持向量維度一致性，不影響數值計算
- **原理**: 零向量在向量空間中代表"無信息"狀態

### 3.3 特徵組合策略

#### 六種特徵組合設計
1. **a-x**: 純結構化數據 (24維)
2. **y**: 純診斷文本 (768維)
3. **z**: 純主訴文本 (768維)  
4. **a-y**: 結構化+診斷文本 (24+768=792維)
5. **a-x,z**: 結構化+主訴文本 (24+768=792維)
6. **a-z**: 結構化+診斷+主訴 (24+768+768=1560維)

每種組合旨在評估不同特徵類型的獨立效果和協同效應。

## 4. 交叉驗證方法

### 4.1 交叉驗證設計
- **方法**: 10-fold 分層交叉驗證 (StratifiedKFold)
- **分層策略**: 保持每個fold中敗血症比例一致
- **隨機種子**: random_state=42，確保結果可重現
- **shuffle**: True，隨機打亂樣本順序

### 4.2 避免數據洩漏的改進交叉驗證

#### 問題識別
原始交叉驗證在整個訓練集上計算填補統計值，然後在每個fold中使用相同統計值，造成數據洩漏。

#### 改進方案
實施自定義交叉驗證，在每個fold內部：
1. 重新分割訓練和驗證數據
2. 僅在fold訓練集上計算缺失值填補統計
3. 將統計值應用於fold驗證集
4. 確保每個fold驗證集只使用該fold訓練集信息

### 4.3 評估指標
- **AUC**: ROC曲線下面積，評估整體分類能力
- **Precision**: 精確率，評估陽性預測準確性
- **Recall**: 召回率，評估敗血症檢出能力  
- **F1-score**: 精確率與召回率的調和平均，平衡指標

## 5. 降維處理

### 5.1 維度問題識別
- **問題核心**: 768維文本嵌入 vs 1257筆樣本
- **表現症狀**: RF在a-y組合中F1從0.886降至0.611
- **根本原因**: 高維特徵空間稀疏，模型過擬合，樣本密度不足

### 5.2 PCA降維策略

#### 降維參數與效果
- **目標維度**: 30維（從768維大幅縮減）
- **診斷文本降維效果**: 768維 → 30維，保留變異量74.5%
- **主訴文本降維效果**: 768維 → 30維，保留變異量78.4%
- **整體效果**: 96%的維度削減，保留主要信息模式

#### PCA實施細節
- **擬合策略**: 僅在訓練集上擬合PCA轉換器
- **應用範圍**: 測試集使用訓練集擬合的轉換器
- **隨機種子**: random_state=42保證可重現性

### 5.3 降維必要性與效果

#### 技術必要性
1. **解決維度災難**: 當特徵數接近或超過樣本數時的經典機器學習問題
2. **降低計算複雜度**: 提升訓練和預測效率
3. **減少過擬合風險**: 移除雜訊特徵，保留主要模式
4. **改善模型泛化**: 特別對隨機森林等算法效果顯著

## 6. 類別不平衡處理

### 6.1 不平衡問題分析
- **實際分布**: 敗血症318例 vs 非敗血症1568例
- **不平衡比例**: 1:4.93 (近似1:5)
- **影響表現**: 純文本特徵組合中多數模型F1=0.000
- **根本原因**: 模型傾向於預測多數類別，忽略少數類別模式

### 6.2 SMOTE過採樣技術

#### 技術原理與應用
使用SMOTETomek技術結合SMOTE過採樣和Tomek Links清理：
- **SMOTE部分**: 在特徵空間中為少數類別生成合成樣本
- **Tomek Links**: 清理邊界模糊的樣本對
- **應用場景**: 純文本特徵組合 (y, z特徵)
- **效果**: 平衡正負樣本比例，提升少數類別識別能力

#### 實施策略
- 每個交叉驗證fold內部獨立應用SMOTE
- 避免在結構化特徵組合中使用（已有良好表現）
- 保持測試集原始分布不變

### 6.3 類別權重平衡

#### 權重機制
所有支援的模型加入class_weight='balanced'參數：
- **自動計算**: sklearn自動根據類別分布計算權重
- **計算原理**: 權重 = 樣本總數 / (類別數 × 該類別樣本數)
- **效果**: 提高少數類別重要性，改善召回率

#### 適用模型
決策樹、支持向量機、隨機森林、邏輯回歸、SGD分類器均支援類別權重平衡。

## 7. 正則化調整

### 7.1 神經網路正則化策略

#### L2正則化參數調整
- **基礎ANN**: alpha=0.001，hidden_layer_sizes=(100, 50)
- **深層NN**: alpha=0.0001，hidden_layer_sizes=(200, 100, 50)
- **學習率**: learning_rate_init=0.001

#### 早停機制
- **監控對象**: 驗證集性能指標
- **停止條件**: 連續epochs無改善時自動停止
- **防過擬合**: 避免在訓練集上過度優化
- **驗證比例**: validation_fraction=0.1

### 7.2 線性模型正則化

#### 邏輯回歸優化
- **最大迭代**: max_iter=2000（確保收斂）
- **求解器**: solver='liblinear'（適合小數據集）
- **正則化**: 默認L2正則化

#### SGD正則化設定
- **正則化強度**: alpha=0.001
- **學習率策略**: learning_rate='adaptive'
- **初始學習率**: eta0=0.01
- **損失函數**: loss='log_loss'

### 7.3 正則化效果與意義

#### 醫療應用考量
1. **防止過擬合**: 特別在高維特徵空間中至關重要
2. **改善泛化能力**: 提升在未見數據上的表現
3. **穩定訓練過程**: 避免梯度爆炸等數值問題
4. **提升模型可靠性**: 醫療應用對穩定性要求極高

## 8. 機器學習模型架構

### 8.1 模型選擇策略
選擇七種不同類型的機器學習算法，涵蓋不同學習範式：

1. **DT (Decision Tree)**: 決策樹 - 高可解釋性，適合醫療決策
2. **SVM (Support Vector Machine)**: 支持向量機 - 高維數據效果優異
3. **RF (Random Forest)**: 隨機森林 - 集成學習，抗過擬合
4. **ANN (Artificial Neural Network)**: 人工神經網路 - 非線性模式識別
5. **LR (Logistic Regression)**: 邏輯回歸 - 線性基準模型
6. **NN (Neural Network)**: 深層神經網路 - 複雜模式學習能力
7. **SGD (Stochastic Gradient Descent)**: 隨機梯度下降 - 大規模數據處理


## 9. 消融研究設計

### 9.1 特徵重要性系統分析
通過六種特徵組合的系統性比較：
- **純特徵效果**: 評估a-x、y、z各自的獨立貢獻
- **組合效果**: 分析a-y、a-x,z、a-z的協同效應
- **特徵互補性**: 量化不同特徵類型間的互補程度

### 9.2 技術改進效果驗證
- **降維效果**: 比較原始768維vs PCA 30維的性能差異
- **平衡處理**: 評估SMOTE和類別權重對不平衡問題的改善
- **模型適應性**: 分析不同算法對各種特徵組合的適應能力

