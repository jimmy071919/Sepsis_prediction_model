import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.impute import SimpleImputer
import joblib
import os
import warnings
warnings.filterwarnings('ignore')

from load_data import load_data

class CrossValidationTrainer:
    """ä½¿ç”¨10-foldäº¤å‰é©—è­‰çš„æ¨¡å‹è¨“ç·´å™¨"""
    
    def __init__(self, random_state=42, n_folds=10):
        """
        åˆå§‹åŒ–äº¤å‰é©—è­‰è¨“ç·´å™¨
        
        Args:
            random_state: éš¨æ©Ÿç¨®å­
            n_folds: äº¤å‰é©—è­‰æŠ˜æ•¸
        """
        self.random_state = random_state
        self.n_folds = n_folds
        self.models = self._initialize_models()
        self.cv_results = {}
        self.test_results = {}
        self.trained_models = {}  # å„²å­˜è¨“ç·´å¥½çš„æ¨¡å‹
        # åˆå§‹åŒ–æ•¸æ“šå¡«å……å™¨ (ç”¨æ–¼è™•ç†NaNå€¼)
        self.imputer = SimpleImputer(strategy='median')
        # åˆå§‹åŒ–äº¤å‰é©—è­‰ç­–ç•¥
        self.cv_strategy = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)
        
    def _initialize_models(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        models = {
            'DT': DecisionTreeClassifier(random_state=self.random_state, max_depth=10),
            'SVM': SVC(random_state=self.random_state, probability=True, kernel='rbf', C=1.0),
            'RF': RandomForestClassifier(random_state=self.random_state, n_estimators=50, max_depth=10),
            'ANN': MLPClassifier(random_state=self.random_state, hidden_layer_sizes=(50,), 
                                max_iter=300, early_stopping=True, validation_fraction=0.1),
            'LR': LogisticRegression(random_state=self.random_state, max_iter=1000, solver='liblinear'),
            'NN': MLPClassifier(random_state=self.random_state, hidden_layer_sizes=(100, 50, 25), 
                               max_iter=500, early_stopping=True, validation_fraction=0.1, alpha=0.01),
            'SGD': SGDClassifier(random_state=self.random_state, max_iter=1000, loss='log_loss', alpha=0.01)
        }
        return models
    
    def _get_scoring_metrics(self):
        """å®šç¾©è©•ä¼°æŒ‡æ¨™"""
        scoring = {
            'auc': 'roc_auc',
            'precision': make_scorer(precision_score, average='binary', zero_division=0),
            'recall': make_scorer(recall_score, average='binary', zero_division=0),
            'f1': make_scorer(f1_score, average='binary', zero_division=0)
        }
        return scoring
    
    def _custom_cross_validate(self, model, X, y, feature_type):
        """è‡ªå®šç¾©äº¤å‰é©—è­‰ï¼Œåœ¨æ¯å€‹foldå…§éƒ¨æ­£ç¢ºè™•ç†NaNå€¼"""
        from sklearn.base import clone
        
        cv_scores = {'auc': [], 'precision': [], 'recall': [], 'f1': []}
        
        for fold_idx, (train_idx, val_idx) in enumerate(self.cv_strategy.split(X, y)):
            print(f"    è™•ç† Fold {fold_idx + 1}/{self.n_folds}...")
            
            # åˆ†å‰²ç•¶å‰foldçš„æ•¸æ“š
            X_fold_train, X_fold_val = X[train_idx], X[val_idx]
            y_fold_train, y_fold_val = y[train_idx], y[val_idx]
            
            # åœ¨ç•¶å‰foldçš„è¨“ç·´é›†ä¸Šè™•ç†NaNå€¼
            if np.isnan(X_fold_train).any() or np.isnan(X_fold_val).any():
                fold_imputer = SimpleImputer(strategy='median')
                X_fold_train = fold_imputer.fit_transform(X_fold_train)
                X_fold_val = fold_imputer.transform(X_fold_val)
            
            # è¨“ç·´æ¨¡å‹
            fold_model = clone(model)
            fold_model.fit(X_fold_train, y_fold_train)
            
            # é æ¸¬
            y_pred = fold_model.predict(X_fold_val)
            y_prob = fold_model.predict_proba(X_fold_val)[:, 1] if hasattr(fold_model, 'predict_proba') else fold_model.decision_function(X_fold_val)
            
            # è¨ˆç®—æŒ‡æ¨™
            cv_scores['auc'].append(roc_auc_score(y_fold_val, y_prob))
            cv_scores['precision'].append(precision_score(y_fold_val, y_pred, average='binary', zero_division=0))
            cv_scores['recall'].append(recall_score(y_fold_val, y_pred, average='binary', zero_division=0))
            cv_scores['f1'].append(f1_score(y_fold_val, y_pred, average='binary', zero_division=0))
        
        # è½‰æ›ç‚ºnumpyæ•¸çµ„
        for metric in cv_scores:
            cv_scores[metric] = np.array(cv_scores[metric])
        
        return cv_scores
    
    def load_and_prepare_data(self, feature_type):
        """è¼‰å…¥å’Œæº–å‚™æŒ‡å®šç‰¹å¾µé¡å‹çš„æ•¸æ“š"""
        try:
            # è¼‰å…¥çµæ§‹åŒ–æ•¸æ“š
            X_train_structured = np.load('structured_data_embedding/x_train_ax_scaled.npy')
            X_test_structured = np.load('structured_data_embedding/x_test_ax_scaled.npy')
            
            # è¼‰å…¥æ–‡æœ¬åµŒå…¥
            X_train_chief = np.load('unstructured_data_embedding/x_train_chief_embed.npy')
            X_test_chief = np.load('unstructured_data_embedding/x_test_chief_embed.npy')
            
            X_train_diagnosis = np.load('unstructured_data_embedding/x_train_diagnosis_embed.npy')
            X_test_diagnosis = np.load('unstructured_data_embedding/x_test_diagnosis_embed.npy')
            
            # è¼‰å…¥æ¨™ç±¤
            y_train = np.load('answer_embedding/y_train.npy')
            y_test = np.load('answer_embedding/y_test.npy')
            
        except FileNotFoundError as e:
            raise FileNotFoundError(f"æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨: {e}")
        
        # æ ¹æ“šç‰¹å¾µé¡å‹çµ„åˆè¨“ç·´å’Œæ¸¬è©¦æ•¸æ“š
        if feature_type == 'a-x':
            X_train = X_train_structured
            X_test = X_test_structured
        elif feature_type == 'y':
            X_train = X_train_chief
            X_test = X_test_chief
        elif feature_type == 'z':
            X_train = X_train_diagnosis
            X_test = X_test_diagnosis
        elif feature_type == 'y-z':
            X_train = np.concatenate([X_train_chief, X_train_diagnosis], axis=1)
            X_test = np.concatenate([X_test_chief, X_test_diagnosis], axis=1)
        elif feature_type == 'a-y':
            X_train = np.concatenate([X_train_structured, X_train_chief], axis=1)
            X_test = np.concatenate([X_test_structured, X_test_chief], axis=1)
        elif feature_type == 'a-x,z':
            X_train = np.concatenate([X_train_structured, X_train_diagnosis], axis=1)
            X_test = np.concatenate([X_test_structured, X_test_diagnosis], axis=1)
        elif feature_type == 'a-z':
            X_train = np.concatenate([X_train_structured, X_train_chief, X_train_diagnosis], axis=1)
            X_test = np.concatenate([X_test_structured, X_test_chief, X_test_diagnosis], axis=1)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„ç‰¹å¾µé¡å‹: {feature_type}")
        
        # æ³¨æ„ï¼šNaNå€¼è™•ç†å·²ç§»è‡³äº¤å‰é©—è­‰å…§éƒ¨ï¼Œé¿å…è³‡æ–™æ´©æ¼
        
        return X_train, X_test, y_train, y_test
    
    def perform_cross_validation(self, feature_type):
        """å°æŒ‡å®šç‰¹å¾µé¡å‹åŸ·è¡Œ10-foldäº¤å‰é©—è­‰"""
        print(f"\\n=== é–‹å§‹ {feature_type} ç‰¹å¾µçš„10-foldäº¤å‰é©—è­‰ ===")
        
        # è¼‰å…¥æ•¸æ“š
        X_train, X_test, y_train, y_test = self.load_and_prepare_data(feature_type)
        
        print(f"è¨“ç·´é›†ç‰¹å¾µçŸ©é™£: {X_train.shape}")
        print(f"æ¸¬è©¦é›†ç‰¹å¾µçŸ©é™£: {X_test.shape}")
        print(f"è¨“ç·´é›†æ¨™ç±¤: {y_train.shape}")
        print(f"æ¸¬è©¦é›†æ¨™ç±¤: {y_test.shape}")
        
        cv_results = {}
        test_results = {}
        
        # å°æ¯å€‹æ¨¡å‹é€²è¡Œäº¤å‰é©—è­‰
        for model_name, model in self.models.items():
            print(f"\\næ­£åœ¨é€²è¡Œ {model_name} æ¨¡å‹çš„10-foldäº¤å‰é©—è­‰...")
            
            try:
                # æª¢æŸ¥æ˜¯å¦éœ€è¦è™•ç†NaNå€¼
                has_nan = feature_type in ['a-x', 'a-y', 'a-x,z', 'a-z'] and np.isnan(X_train).any()
                
                if has_nan:
                    # ä½¿ç”¨è‡ªå®šç¾©çš„äº¤å‰é©—è­‰ä¾†æ­£ç¢ºè™•ç†NaNå€¼
                    cv_scores = self._custom_cross_validate(model, X_train, y_train, feature_type)
                else:
                    # ä½¿ç”¨æ¨™æº–çš„äº¤å‰é©—è­‰
                    scoring = self._get_scoring_metrics()
                    cv_scores_dict = cross_validate(
                        model, X_train, y_train,
                        cv=self.cv_strategy,
                        scoring=scoring,
                        n_jobs=-1,
                        return_train_score=False
                    )
                    # è½‰æ›æ ¼å¼ä»¥åŒ¹é…è‡ªå®šç¾©å‡½æ•¸çš„è¼¸å‡º
                    cv_scores = {
                        'auc': cv_scores_dict['test_auc'],
                        'precision': cv_scores_dict['test_precision'],
                        'recall': cv_scores_dict['test_recall'],
                        'f1': cv_scores_dict['test_f1']
                    }
                
                # è¨ˆç®—äº¤å‰é©—è­‰å¹³å‡åˆ†æ•¸å’Œæ¨™æº–å·®
                cv_result = {
                    'AUC_mean': np.mean(cv_scores['auc']),
                    'AUC_std': np.std(cv_scores['auc']),
                    'precision_mean': np.mean(cv_scores['precision']),
                    'precision_std': np.std(cv_scores['precision']),
                    'recall_mean': np.mean(cv_scores['recall']),
                    'recall_std': np.std(cv_scores['recall']),
                    'f1_mean': np.mean(cv_scores['f1']),
                    'f1_std': np.std(cv_scores['f1'])
                }
                
                cv_results[model_name] = cv_result
                
                print(f"{model_name} äº¤å‰é©—è­‰å®Œæˆ:")
                print(f"  AUC: {cv_result['AUC_mean']:.3f} (Â±{cv_result['AUC_std']:.3f})")
                print(f"  F1: {cv_result['f1_mean']:.3f} (Â±{cv_result['f1_std']:.3f})")
                
                # åœ¨æ•´å€‹è¨“ç·´é›†ä¸Šè¨“ç·´æ¨¡å‹ï¼Œç„¶å¾Œåœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°
                print(f"æ­£åœ¨è¨“ç·´ {model_name} ä¸¦åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°...")
                
                # ç‚ºæœ€çµ‚æ¨¡å‹è¨“ç·´è™•ç†NaNå€¼
                if has_nan:
                    fold_imputer = SimpleImputer(strategy='median')
                    X_train_final = fold_imputer.fit_transform(X_train)
                    X_test_final = fold_imputer.transform(X_test)
                else:
                    X_train_final = X_train
                    X_test_final = X_test
                
                model.fit(X_train_final, y_train)
                
                # ä¿å­˜è¨“ç·´å¥½çš„æ¨¡å‹
                if feature_type not in self.trained_models:
                    self.trained_models[feature_type] = {}
                self.trained_models[feature_type][model_name] = model
                
                # åœ¨æ¸¬è©¦é›†ä¸Šé æ¸¬
                y_test_pred = model.predict(X_test_final)
                y_test_prob = model.predict_proba(X_test_final)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test_final)
                
                # è¨ˆç®—æ¸¬è©¦é›†æŒ‡æ¨™
                test_result = {
                    'AUC': roc_auc_score(y_test, y_test_prob),
                    'precision': precision_score(y_test, y_test_pred, average='binary', zero_division=0),
                    'recall': recall_score(y_test, y_test_pred, average='binary', zero_division=0),
                    'f1': f1_score(y_test, y_test_pred, average='binary', zero_division=0)
                }
                
                test_results[model_name] = test_result
                
                print(f"{model_name} æ¸¬è©¦é›†çµæœ:")
                print(f"  AUC: {test_result['AUC']:.3f}")
                print(f"  F1: {test_result['f1']:.3f}")
                
            except Exception as e:
                print(f"{model_name} è¨“ç·´å¤±æ•—: {str(e)}")
                # å¡«å……ç©ºçµæœ
                empty_cv_result = {
                    'AUC_mean': 0, 'AUC_std': 0,
                    'precision_mean': 0, 'precision_std': 0,
                    'recall_mean': 0, 'recall_std': 0,
                    'f1_mean': 0, 'f1_std': 0
                }
                empty_test_result = {'AUC': 0, 'precision': 0, 'recall': 0, 'f1': 0}
                cv_results[model_name] = empty_cv_result
                test_results[model_name] = empty_test_result
        
        # ä¿å­˜çµæœ
        self.cv_results[feature_type] = cv_results
        self.test_results[feature_type] = test_results
        
        return cv_results, test_results
    
    def run_cross_validation_study(self):
        """åŸ·è¡Œå®Œæ•´çš„äº¤å‰é©—è­‰ç ”ç©¶"""
        feature_types = ['a-x', 'y', 'z', 'y-z', 'a-y', 'a-x,z', 'a-z']
        
        print(f"=== é–‹å§‹ {self.n_folds}-fold äº¤å‰é©—è­‰ç ”ç©¶ ===")
        
        for feature_type in feature_types:
            try:
                self.perform_cross_validation(feature_type)
            except Exception as e:
                print(f"ç‰¹å¾µé¡å‹ {feature_type} äº¤å‰é©—è­‰å¤±æ•—: {str(e)}")
                continue
        
        # ç”Ÿæˆç¸½çµå ±å‘Š
        self.create_summary_report()
    
    def create_summary_report(self):
        """å‰µå»ºäº¤å‰é©—è­‰çµæœç¸½çµå ±å‘Š"""
        print(f"\\n\\n=== {self.n_folds}-fold äº¤å‰é©—è­‰çµæœç¸½çµ ===")
        
        for feature_type in self.cv_results:
            print(f"\\n=== {feature_type} ç‰¹å¾µ ===")
            
            # äº¤å‰é©—è­‰çµæœ
            print(f"\\n{self.n_folds}-fold äº¤å‰é©—è­‰çµæœ (å¹³å‡å€¼ Â± æ¨™æº–å·®):")
            cv_df_data = []
            for model_name, results in self.cv_results[feature_type].items():
                cv_df_data.append({
                    'Model': model_name,
                    'AUC': f"{results['AUC_mean']:.3f} Â± {results['AUC_std']:.3f}",
                    'Precision': f"{results['precision_mean']:.3f} Â± {results['precision_std']:.3f}",
                    'Recall': f"{results['recall_mean']:.3f} Â± {results['recall_std']:.3f}",
                    'F1': f"{results['f1_mean']:.3f} Â± {results['f1_std']:.3f}"
                })
            
            cv_df = pd.DataFrame(cv_df_data)
            print(cv_df.to_string(index=False))
            
            # æ¸¬è©¦é›†çµæœ
            print(f"\\næ¸¬è©¦é›†è©•ä¼°çµæœ:")
            test_df_data = []
            for model_name, results in self.test_results[feature_type].items():
                test_df_data.append({
                    'Model': model_name,
                    'AUC': f"{results['AUC']:.3f}",
                    'Precision': f"{results['precision']:.3f}",
                    'Recall': f"{results['recall']:.3f}",
                    'F1': f"{results['f1']:.3f}"
                })
            
            test_df = pd.DataFrame(test_df_data)
            print(test_df.to_string(index=False))
    
    def save_results_to_xlsx(self):
        """å°‡çµæœä¿å­˜ç‚ºExcelæ–‡ä»¶ï¼Œæ¯å€‹ç‰¹å¾µé¡å‹å°æ‡‰ä¸åŒçš„å·¥ä½œè¡¨"""
        import openpyxl
        from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
        from openpyxl.utils.dataframe import dataframe_to_rows
        from datetime import datetime
        
        # å‰µå»ºExcelæ–‡ä»¶å
        excel_filename = 'result/cross_validation_results.xlsx'
        
        print(f"\nğŸ“Š æ­£åœ¨ä¿å­˜çµæœåˆ° Excel æª”æ¡ˆ: {excel_filename}")
        
        # å‰µå»ºå·¥ä½œç°¿
        wb = openpyxl.Workbook()
        # ç§»é™¤é»˜èªå·¥ä½œè¡¨
        wb.remove(wb.active)
        
        # å®šç¾©æ¨£å¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        border = Border(
            left=Side(border_style="thin"),
            right=Side(border_style="thin"),
            top=Side(border_style="thin"),
            bottom=Side(border_style="thin")
        )
        center_alignment = Alignment(horizontal="center", vertical="center")
        
        # å‰µå»ºæ‘˜è¦å·¥ä½œè¡¨
        summary_ws = wb.create_sheet("ğŸ“Š æ‘˜è¦ç¸½è¦½")
        
        # å¯«å…¥æ‘˜è¦æ¨™é¡Œ
        summary_ws['A1'] = f"æ•—è¡€ç—‡é æ¸¬æ¨¡å‹ {self.n_folds}-fold äº¤å‰é©—è­‰çµæœæ‘˜è¦"
        summary_ws['A1'].font = Font(size=16, bold=True)
        summary_ws['A2'] = f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}"
        summary_ws['A2'].font = Font(size=12, italic=True)
        
        # åˆä½µæ¨™é¡Œå–®å…ƒæ ¼
        summary_ws.merge_cells('A1:H1')
        summary_ws.merge_cells('A2:H2')
        
        summary_row = 4
        
        # ç‚ºæ¯å€‹ç‰¹å¾µé¡å‹å‰µå»ºå·¥ä½œè¡¨ä¸¦ä¿å­˜çµæœ
        for feature_type in self.cv_results:
            print(f"   æ­£åœ¨è™•ç† {feature_type} ç‰¹å¾µ...")
            
            # å‰µå»ºäº¤å‰é©—è­‰çµæœå·¥ä½œè¡¨
            cv_ws_name = f"CV_{feature_type.replace('-', '_').replace(',', '_')}"
            cv_ws = wb.create_sheet(cv_ws_name)
            
            # å‰µå»ºæ¸¬è©¦çµæœå·¥ä½œè¡¨
            test_ws_name = f"Test_{feature_type.replace('-', '_').replace(',', '_')}"
            test_ws = wb.create_sheet(test_ws_name)
            
            # æº–å‚™äº¤å‰é©—è­‰æ•¸æ“š
            cv_data = []
            test_data = []
            
            for model_name in self.cv_results[feature_type]:
                # äº¤å‰é©—è­‰çµæœ
                cv_results = self.cv_results[feature_type][model_name]
                cv_data.append({
                    'Model': model_name,
                    'AUC_mean': round(cv_results['AUC_mean'], 4),
                    'AUC_std': round(cv_results['AUC_std'], 4),
                    'Precision_mean': round(cv_results['precision_mean'], 4),
                    'Precision_std': round(cv_results['precision_std'], 4),
                    'Recall_mean': round(cv_results['recall_mean'], 4),
                    'Recall_std': round(cv_results['recall_std'], 4),
                    'F1_mean': round(cv_results['f1_mean'], 4),
                    'F1_std': round(cv_results['f1_std'], 4)
                })
                
                # æ¸¬è©¦é›†çµæœ
                test_results = self.test_results[feature_type][model_name]
                test_data.append({
                    'Model': model_name,
                    'AUC': round(test_results['AUC'], 4),
                    'Precision': round(test_results['precision'], 4),
                    'Recall': round(test_results['recall'], 4),
                    'F1': round(test_results['f1'], 4)
                })
            
            # å‰µå»ºDataFrame
            cv_df = pd.DataFrame(cv_data)
            test_df = pd.DataFrame(test_data)
            
            # å¯«å…¥äº¤å‰é©—è­‰å·¥ä½œè¡¨
            cv_ws['A1'] = f"{feature_type} ç‰¹å¾µ - {self.n_folds}-fold äº¤å‰é©—è­‰çµæœ"
            cv_ws['A1'].font = Font(size=14, bold=True)
            cv_ws.merge_cells('A1:I1')
            
            # å¯«å…¥CVæ•¸æ“š
            for r in dataframe_to_rows(cv_df, index=False, header=True):
                cv_ws.append(r)
            
            # å¯«å…¥æ¸¬è©¦çµæœå·¥ä½œè¡¨
            test_ws['A1'] = f"{feature_type} ç‰¹å¾µ - æ¸¬è©¦é›†è©•ä¼°çµæœ"
            test_ws['A1'].font = Font(size=14, bold=True)
            test_ws.merge_cells('A1:E1')
            
            # å¯«å…¥æ¸¬è©¦æ•¸æ“š
            for r in dataframe_to_rows(test_df, index=False, header=True):
                test_ws.append(r)
            
            # æ ¼å¼åŒ–äº¤å‰é©—è­‰å·¥ä½œè¡¨
            self._format_worksheet(cv_ws, cv_df.shape[0] + 2, cv_df.shape[1], 
                                 header_font, header_fill, border, center_alignment)
            
            # æ ¼å¼åŒ–æ¸¬è©¦çµæœå·¥ä½œè¡¨
            self._format_worksheet(test_ws, test_df.shape[0] + 2, test_df.shape[1], 
                                 header_font, header_fill, border, center_alignment)
            
            # åœ¨æ‘˜è¦å·¥ä½œè¡¨ä¸­æ·»åŠ æœ€ä½³çµæœ
            summary_ws[f'A{summary_row}'] = f"{feature_type} ç‰¹å¾µæœ€ä½³çµæœ:"
            summary_ws[f'A{summary_row}'].font = Font(bold=True)
            summary_row += 1
            
            # æ‰¾å‡ºæœ€ä½³AUCçµæœ
            best_cv_auc = max(cv_data, key=lambda x: x['AUC_mean'])
            best_test_auc = max(test_data, key=lambda x: x['AUC'])
            
            summary_ws[f'B{summary_row}'] = f"äº¤å‰é©—è­‰æœ€ä½³AUC: {best_cv_auc['Model']} ({best_cv_auc['AUC_mean']:.4f} Â± {best_cv_auc['AUC_std']:.4f})"
            summary_row += 1
            summary_ws[f'B{summary_row}'] = f"æ¸¬è©¦é›†æœ€ä½³AUC: {best_test_auc['Model']} ({best_test_auc['AUC']:.4f})"
            summary_row += 2
        
        # èª¿æ•´æ‘˜è¦å·¥ä½œè¡¨åˆ—å¯¬
        from openpyxl.utils import get_column_letter
        for col_idx in range(1, 9):  # å‡è¨­æœ€å¤š8åˆ—
            max_length = 0
            column_letter = get_column_letter(col_idx)
            
            # æª¢æŸ¥é€™ä¸€åˆ—çš„æ‰€æœ‰å–®å…ƒæ ¼ä¾†è¨ˆç®—æœ€å¤§é•·åº¦
            for row in range(1, summary_row + 1):
                try:
                    cell = summary_ws.cell(row=row, column=col_idx)
                    if cell.value and hasattr(cell, 'value'):
                        max_length = max(max_length, len(str(cell.value)))
                except:
                    pass
            
            # è¨­å®šåˆ—å¯¬
            if max_length > 0:
                summary_ws.column_dimensions[column_letter].width = min(max_length + 2, 50)
        
        # ä¿å­˜Excelæ–‡ä»¶
        wb.save(excel_filename)
        
        print(f"âœ… çµæœå·²æˆåŠŸä¿å­˜åˆ° {excel_filename}")
        print(f"ğŸ“‹ åŒ…å« {len(self.cv_results)} å€‹ç‰¹å¾µçµ„åˆçš„è©³ç´°çµæœ")
        print(f"ğŸ“Š æ¯å€‹ç‰¹å¾µçµ„åˆéƒ½æœ‰ç¨ç«‹çš„äº¤å‰é©—è­‰å’Œæ¸¬è©¦çµæœå·¥ä½œè¡¨")
    
    def _format_worksheet(self, ws, num_rows, num_cols, header_font, header_fill, border, center_alignment):
        """æ ¼å¼åŒ–å·¥ä½œè¡¨"""
        # æ ¼å¼åŒ–æ¨™é¡Œè¡Œ
        for col in range(1, num_cols + 1):
            cell = ws.cell(row=2, column=col)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = center_alignment
            cell.border = border
        
        # æ ¼å¼åŒ–æ•¸æ“šè¡Œ
        for row in range(3, num_rows + 1):
            for col in range(1, num_cols + 1):
                cell = ws.cell(row=row, column=col)
                cell.border = border
                cell.alignment = center_alignment
        
        # èª¿æ•´åˆ—å¯¬ - ä¿®å¾©åˆä½µå–®å…ƒæ ¼å•é¡Œ
        from openpyxl.utils import get_column_letter
        for col_idx in range(1, num_cols + 1):
            max_length = 0
            column_letter = get_column_letter(col_idx)
            
            # æª¢æŸ¥é€™ä¸€åˆ—çš„æ‰€æœ‰å–®å…ƒæ ¼ä¾†è¨ˆç®—æœ€å¤§é•·åº¦
            for row in range(1, num_rows + 1):
                cell = ws.cell(row=row, column=col_idx)
                if cell.value and not isinstance(cell, type(ws.merged_cells)):
                    max_length = max(max_length, len(str(cell.value)))
            
            # è¨­å®šåˆ—å¯¬
            ws.column_dimensions[column_letter].width = min(max_length + 2, 20)
    
    def save_trained_models(self):
        """ä¿å­˜æ‰€æœ‰è¨“ç·´å¥½çš„æ¨¡å‹åˆ°æª”æ¡ˆ"""
        if not os.path.exists('models'):
            os.makedirs('models')
        
        print(f"\nğŸ¤– æ­£åœ¨ä¿å­˜è¨“ç·´å¥½çš„æ¨¡å‹...")
        
        saved_count = 0
        for feature_type in self.trained_models:
            for model_name, model in self.trained_models[feature_type].items():
                # å‰µå»ºæ¨¡å‹æª”å
                model_filename = f'models/{feature_type.replace("-", "_").replace(",", "_")}_{model_name}.pkl'
                
                # ä¿å­˜æ¨¡å‹
                joblib.dump(model, model_filename)
                saved_count += 1
                print(f"   âœ… {feature_type}-{model_name} æ¨¡å‹å·²ä¿å­˜: {model_filename}")
        
        print(f"\nğŸ“ ç¸½å…±ä¿å­˜äº† {saved_count} å€‹è¨“ç·´å¥½çš„æ¨¡å‹åˆ° models/ ç›®éŒ„")
        print(f"ğŸ’¡ ä½¿ç”¨ joblib.load('æ¨¡å‹è·¯å¾‘') ä¾†è¼‰å…¥æ¨¡å‹é€²è¡Œé æ¸¬")
        
        # å‰µå»ºæ¨¡å‹ä½¿ç”¨èªªæ˜æª”æ¡ˆ
        self._create_model_usage_guide()
    
    def _create_model_usage_guide(self):
        """å‰µå»ºæ¨¡å‹ä½¿ç”¨èªªæ˜æª”æ¡ˆ"""
        guide_content = '''# è¨“ç·´æ¨¡å‹ä½¿ç”¨èªªæ˜

## æ¨¡å‹æª”æ¡ˆèªªæ˜

æœ¬ç›®éŒ„åŒ…å«äº†æ•—è¡€ç—‡é æ¸¬æ¨¡å‹çš„æ‰€æœ‰è¨“ç·´å¥½çš„æ¨¡å‹æª”æ¡ˆã€‚

### æª”æ¡ˆå‘½åè¦å‰‡
- æ ¼å¼: `{ç‰¹å¾µé¡å‹}_{æ¨¡å‹åç¨±}.pkl`
- ç‰¹å¾µé¡å‹:
  - `a_x`: åƒ…çµæ§‹åŒ–æ•¸æ“šç‰¹å¾µ
  - `y`: åƒ…ä¸»è¨´æ–‡æœ¬åµŒå…¥
  - `z`: åƒ…è¨ºæ–·æ–‡æœ¬åµŒå…¥
  - `a_y`: çµæ§‹åŒ–æ•¸æ“š + ä¸»è¨´æ–‡æœ¬
  - `a_x_z`: çµæ§‹åŒ–æ•¸æ“š + è¨ºæ–·æ–‡æœ¬
  - `a_z`: çµæ§‹åŒ–æ•¸æ“š + ä¸»è¨´æ–‡æœ¬ + è¨ºæ–·æ–‡æœ¬
- æ¨¡å‹åç¨±: DT(æ±ºç­–æ¨¹), SVM(æ”¯æŒå‘é‡æ©Ÿ), RF(éš¨æ©Ÿæ£®æ—), ANN(äººå·¥ç¥ç¶“ç¶²è·¯), LR(é‚è¼¯å›æ­¸), NN(ç¥ç¶“ç¶²è·¯), SGD(éš¨æ©Ÿæ¢¯åº¦ä¸‹é™)

### è¼‰å…¥å’Œä½¿ç”¨æ¨¡å‹

```python
import joblib
import numpy as np

# è¼‰å…¥æ¨¡å‹
model = joblib.load('models/a_z_RF.pkl')  # ä¾‹å¦‚è¼‰å…¥æœ€ä½³çµ„åˆçš„éš¨æ©Ÿæ£®æ—æ¨¡å‹

# æº–å‚™é æ¸¬æ•¸æ“š (éœ€è¦å’Œè¨“ç·´æ™‚ç›¸åŒçš„ç‰¹å¾µé †åºå’Œæ ¼å¼)
X_new = np.array([...])  # æ–°çš„ç—…æ‚£æ•¸æ“š

# é€²è¡Œé æ¸¬
y_pred = model.predict(X_new)  # é æ¸¬é¡åˆ¥ (0: ç„¡æ•—è¡€ç—‡, 1: æœ‰æ•—è¡€ç—‡)
y_prob = model.predict_proba(X_new)[:, 1]  # é æ¸¬æ¦‚ç‡

print(f"é æ¸¬çµæœ: {y_pred[0]}")
print(f"æ•—è¡€ç—‡æ¦‚ç‡: {y_prob[0]:.3f}")
```

### æ³¨æ„äº‹é …
1. ä½¿ç”¨æ¨¡å‹å‰éœ€ç¢ºä¿è¼¸å…¥æ•¸æ“šçš„é è™•ç†èˆ‡è¨“ç·´æ™‚ä¸€è‡´
2. çµæ§‹åŒ–æ•¸æ“šéœ€è¦ç¶“éç›¸åŒçš„æ¨™æº–åŒ–è™•ç†
3. æ–‡æœ¬æ•¸æ“šéœ€è¦ç¶“éç›¸åŒçš„BERTåµŒå…¥è™•ç†
4. å»ºè­°ä½¿ç”¨äº¤å‰é©—è­‰çµæœä¸­è¡¨ç¾æœ€ä½³çš„æ¨¡å‹çµ„åˆ
'''
        
        with open('models/README.md', 'w', encoding='utf-8') as f:
            f.write(guide_content)
        
        print(f"ğŸ“ æ¨¡å‹ä½¿ç”¨èªªæ˜å·²ä¿å­˜: models/README.md")
